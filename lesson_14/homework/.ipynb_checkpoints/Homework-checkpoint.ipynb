{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 13\n",
    "\n",
    "In this homework you are going to build your first classifier for the CIFAR-10 dataset. This dataset contains 10 different classes and you can learn more about it [here](https://www.cs.toronto.edu/~kriz/cifar.html). This homework consists of the following tasks:\n",
    "* Dataset inspection\n",
    "* Building the network\n",
    "* Training\n",
    "* Evaluation\n",
    "\n",
    "At the end, as usual, there will be a couple of questions for you to answer :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 20:28:08.862215: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-18 20:28:08.882061: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-18 20:28:09.064886: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-18 20:28:09.066008: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-18 20:28:09.664373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/olenabiryukova/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Input, MaxPooling2D\n",
    "from tensorflow.keras import Model\n",
    "from time import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "# Set the seeds for reproducibility\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "seed_value = 1234578790\n",
    "seed(seed_value)\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Dataset Inspection\n",
    "\n",
    "Load the dataset and make a quick inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "162971648/170498071 [===========================>..] - ETA: 1s"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "# Mapping from class ID to class name\n",
    "classes = {0:'plane', 1:'car', 2:'bird', 3:'cat', 4:'deer',\n",
    "           5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "\n",
    "# Dataset params\n",
    "num_classes = len(classes)\n",
    "size = x_train.shape[1]\n",
    "\n",
    "# Visualize random samples (as a plot with 3x6 samples)\n",
    "for ii in range(18):    \n",
    "    plt.subplot(3,6,ii+1)\n",
    "    # Pick a random sample\n",
    "    idx = 0\n",
    "    # Show the image and the label\n",
    "    plt.imshow(x_train[idx, ...])\n",
    "    plt.title(classes[int(y_train[idx])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the class histogram (you can visualize it if you want). Is the dataset balanced?\n",
    "\n",
    "Hint: You might find [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) tool useful. In any case, it's up to you how you compute the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the class histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation\n",
    "\n",
    "In this step, you'll need to prepare the data for training, i.e., you will have to normalize it and encode the labels as one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "x_train =\n",
    "x_test =\n",
    "\n",
    "# One-hot encoding\n",
    "y_train =\n",
    "y_test =\n",
    "\n",
    "print('Train set:   ', len(y_train), 'samples')\n",
    "print('Test set:    ', len(y_test), 'samples')\n",
    "print('Sample dims: ', x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Building the Classifier\n",
    "\n",
    "Build the CNN for CIFAR10 classification. For starters, you can use the same network we used in the lesson for the MNIST problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the classifier\n",
    "model =\n",
    "\n",
    "# Show the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Training\n",
    "\n",
    "Compile the model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "# Train the model\n",
    "history ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training history (this cell is complete, nothing to implement here :-) )\n",
    "h = history.history\n",
    "epochs = range(len(h['loss']))\n",
    "\n",
    "plt.subplot(121), plt.plot(epochs, h['loss'], '.-', epochs, h['val_loss'], '.-')\n",
    "plt.grid(True), plt.xlabel('epochs'), plt.ylabel('loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.subplot(122), plt.plot(epochs, h['accuracy'], '.-',\n",
    "                           epochs, h['val_accuracy'], '.-')\n",
    "plt.grid(True), plt.xlabel('epochs'), plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "print('Train Acc     ', h['accuracy'][-1])\n",
    "print('Validation Acc', h['val_accuracy'][-1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluation\n",
    "\n",
    "In this step, you have to calculate the accuracies and visualize some random samples. For the evaluation, you are going to use the test split from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the labels and the predictions as sparse values\n",
    "y_true = \n",
    "y_pred ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the accuracy for each class\n",
    "for class_id, class_name in classes.items():\n",
    "    \n",
    "    acc =\n",
    "    print(class_name, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the overall stats\n",
    "ev = model.evaluate(x_test, y_test)\n",
    "print('Test loss  ', ev[0])\n",
    "print('Test metric', ev[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random samples\n",
    "for ii in range(15):\n",
    "    # Pick a random sample\n",
    "    idx =\n",
    "    # Show the results\n",
    "    plt.subplot(3,5,ii+1), plt.imshow(x_test[idx, ...])\n",
    "    plt.title('True: ' + str(classes[y_true[idx]]) + ' | Pred: ' + str(classes[y_pred[idx]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* What is the overall accuracy of the classifier?\n",
    "* What modifications would you do in order to improve the classification accuracy?\n",
    "* Make **one** modification (that you think can help) and train the classifier again. Does the accuracy improve?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
